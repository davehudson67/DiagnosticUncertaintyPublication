---
title: "Peril 3"
author: "Dave Hudson"
date: "2024-05-01"
output:
html_document:
df_print: paged
---

# R Code for Peril 3: Flipping parameters

#### Load libaries and set wd.

```{r setup, message = FALSE}
library(nimble)
library(MCMCvis)
library(tidyverse)
library(coda)

setwd("~")
```

#### Setup test parameters and save truths

#### Set sensitivities and specificities for three different tests and prevalence for a single populations of 1000 individuals.

```{r, message = FALSE}
psens <- c(0.9, 0.9, 0.9)
pspec <- c(0.75, 0.75, 0.75)
pprev <- 0.3
nindividuals <- 1000
ntests <- 3
true_values <- c(pprev, psens[1], pspec[1])
true_parameter <- c("Prevalence", "Sensitivity", "Specificity")
truth <- data.frame(true_parameter, true_values)  
```

#### Now we loop over the analysis five times and save the output.

```{r, message = FALSE, results='hide'}

# Loop to run the simulation 5 times
for(run_number in 1:5) {
  
  # Simulate infection status of the individuals
  inf <- rbinom(nindividuals, 1, pprev)
  
  # Set up empty array of test outcomes
  tests <- array(0, dim = c(nindividuals, length(psens)))
  colnames(tests) <- c("test1", "test2", "test3")
  
  # Simulate test outcome for each badger and each test
  for(i in 1:length(inf)) {
    for(j in 1:length(psens)) {
      tests[i, j] <- rbinom(1, 1, ifelse(inf[i] == 1, psens[j], 1-pspec[j]))
    }
  }
  
  # Get table of frequencies
  binop <- 2^seq(0, ntests-1)
  testbin <- tests[, 1:ntests] %*% binop
  testcounts <- tabulate(testbin + 1, nbins = 2^ntests)
  
  # Create omega matrix of binary sequence
  omega <- expand.grid(replicate(ntests, c(0, 1), simplify = FALSE))
  omega <- as.matrix(omega)
  omega <- t(omega)
  
  # Define parameters you want to report on
  params <- c("pprev", "psens", "pspec")
  
  # Nimble model setup
  code  <- nimbleCode({
    for(i in 1:n) {
      pinf[i] <- pprev * prod(omega[1:nT, i] * psens[1:nT] + (1 - omega[1:nT, i]) * (1 - psens[1:nT])) +
        (1 - pprev) * prod(omega[1:nT, i] * (1 - pspec[1:nT]) + (1 - omega[1:nT, i]) * (pspec[1:nT]))
    }
    
    Te[1:n] ~ dmulti(pinf[1:n], N)
    
    pprev ~ dunif(0,1)
    for(j in 1:nT) {
      psens[j] ~ dunif(0, 1)
      pspec[j] ~ dunif(0, 1)
    }
  })
  
  consts <- list(n = length(testcounts), nT = ntests, N = sum(testcounts), omega = omega)
  data <- list(Te = testcounts)
  inits <- list(pprev = runif(1, 0, 1), psens = runif(ntests, 0, 1), pspec = runif(ntests, 0, 1))
  
  model <- nimbleModel(code, constants = consts, data = data, inits = inits)
  cModel <- compileNimble(model)
  config <- configureMCMC(model)
  rMCMC <- buildMCMC(config)
  cMCMC <- compileNimble(rMCMC, project = model)
  
  # Run the MCMC
  system.time(run <- runMCMC(cMCMC, 
                             niter = 500000, 
                             nburnin = 24000, 
                             nchains = 3, 
                             progressBar = TRUE, 
                             summary = TRUE, 
                             samplesAsCodaMCMC = TRUE, 
                             thin = 1))
  
  # Save the output to a unique file
  file_name <- paste0("run", run_number, ".rds")
  saveRDS(run, file = file_name)
}

```

#### Now process those results into one large dataframe and get ready to plot

```{r, message = FALSE}

## Process the output data
n_runs <- 5
data_frames <- list()  # List to store data frames from each run

# Loop to process each run
for (i in 1:n_runs) {
  # Construct the filename based on the loop index
  filename <- paste0("run", i, ".rds")
  
  # Read each RDS file
  run <- readRDS(filename)
  
  # Process the summary and samples
  run_sum <- as.matrix(run$summary$all.chains[, 1])
  run_samp <- as.matrix(run$samples)
  
  # Transform the samples dataframe
  run_samp <- run_samp %>%
    as.data.frame() %>%
    rename(pprev = 1, psens = 2, psens2 = 3, psens3 = 4, pspec = 5, pspec2 = 6, pspec3 = 7) %>%
    pivot_longer(cols = c(pprev, psens, pspec),  values_to = "Estimate", names_to = "Inferred_parameter" ) %>%
    mutate(Realisation = i) %>%
    select(Inferred_parameter, Estimate, Realisation) %>%
    mutate(Truth = rep(c(0.3, 0.9, 0.75), times = 4284000/3)) %>%
    mutate(Mean = rep(c(run_sum[1], run_sum[2], run_sum[5]), times = 4284000/3))

  # Store the processed data frame in the list
  data_frames[[i]] <- run_samp
}

```

#### We can now do a bit of tidying and create the plot.

```{r, message = FALSE}

# Combine all data frames into one final data frame
data <- bind_rows(data_frames)

data$Realisation <- as.factor(data$Realisation)
data <- data %>%
  mutate(Inferred_parameter = rep(c("Prevalence", "Sensitivity", "Specificity"), times = 21420000/3))

ggplot(data, aes(x = Inferred_parameter, y = Estimate, fill = Inferred_parameter)) +
  geom_violin(position = "dodge") +
  geom_hline(aes(yintercept = Truth, colour = Inferred_parameter), linetype = 2) +
  stat_summary(fun = "mean", geom = "point") +
  facet_grid(~ Realisation) +
  theme_bw() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), text = element_text(size = 15)) +
  labs(x = "Realisation", fill = "Inferred parameter", colour = "Inferred parameter")
```

### Adding a third test

#### Setup test parameters and save truths

#### Set sensitivities and specificities for three different tests and prevalence for a single populations of 1000 individuals.


```{r, message=FALSE}

## Set up a three test scenario with the 3rd test being very poor
psens <- c(0.9, 0.9, 0.1)
pspec <- c(0.75, 0.75, 0.05)
pprev <- 0.3
nindividuals <- 1000
true_values <- c(pprev, psens[1], pspec[1])
true_parameter <- c("Prevalence", "Sensitivity", "Specificity")
truth <- data.frame(true_parameter, true_values)  
```

#### Simulate test outcomes

```{r, message=FALSE}

#simulate infection status
inf <- rbinom(nindividuals, 1, pprev)

#set up empty array of test outcomes
tests <- array(0, dim = c(nindividuals, length(psens)))
colnames(tests) <- c("test1", "test2", "test3")

#for each badger and each test, simulate test outcome
for(i in 1:length(inf)){
  for(j in 1:length(psens)){
    tests[i, j] <- rbinom(1, 1, ifelse(inf[i] == 1, psens[j], 1-pspec[j]))}}

###choose number of tests to infer results from
ntests <- 3

#get table of frequencies
binop <- 2^seq(0, ntests-1)
testbin <- tests[, 1:ntests] %*% binop
testcounts <- tabulate(testbin + 1, nbins = 2^ntests)

#create omega matrix of binary sequence
omega <- expand.grid(replicate(ntests, c(0, 1), simplify = FALSE))
omega <- as.matrix(omega)
omega <- t(omega)

## Define parameters to report on
params <- c("pprev", "psens", "pspec")
```

#### Run the analysis with 3 test scenario and save the output.

```{r, message=FALSE}

code <- nimbleCode({
  
  for(i in 1:n) {
    pinf[i] <- pprev * prod(omega[1:nT, i] * psens[1:nT] + (1 - omega[1:nT, i]) * (1 - psens[1:nT])) +
      (1 - pprev) * prod(omega[1:nT, i] * (1 - pspec[1:nT]) + (1 - omega[1:nT, i]) * (pspec[1:nT]))
  }
  
  Te[1:n] ~ dmulti(pinf[1:n], N)
  
  pprev ~ dunif(0,1)
  
  # Specify different priors for each psens
  psens[1] ~ dunif(0, 1)
  psens[2] ~ dunif(0, 1)
  psens[3] ~ dunif(0, 0.5)
  
  for(j in 1:nT) {
    pspec[j] ~ dunif(0, 1)
  }
  
})

consts <- list(n = length(testcounts),
               nT = ntests, N = sum(testcounts), omega = omega)

data <- list(
  Te = testcounts)

inits <- list(
  pprev = runif(1, 0, 1),
  psens = c(runif(1, 0.5, 1), runif(1, 0, 1), runif(1, 0, 0.5)),
  pspec = runif(ntests, 0, 1)
)

model <- nimbleModel(code, constants = consts, data = data, inits = inits)

cModel <- compileNimble(model)

config <- configureMCMC(model)

rMCMC <- buildMCMC(config)

cMCMC <- compileNimble(rMCMC, project = model)

system.time(run <- runMCMC(cMCMC, 
                           niter = 500000, 
                           nburnin = 24000, 
                           nchains = 3, 
                           progressBar = TRUE, 
                           summary = TRUE, 
                           samplesAsCodaMCMC = TRUE, 
                           thin = 1))

saveRDS(run, file = "run1_3test.rds")

```

#### Now run the 2 test scenario, first setting the parameters and then running the model.

```{r, message=FALSE}

## 2 test scenario

psens <- c(0.9, 0.9)
pspec <- c(0.75, 0.75)
pprev <- 0.3
nindividuals <- 1000
true_values <- c(pprev, psens[1], pspec[1])
true_parameter <- c("Prevalence", "Sensitivity", "Specificity")
truth <- data.frame(true_parameter, true_values)  

#simulate infection status of the badgers
inf <- rbinom(nindividuals, 1, pprev)

#set up empty array of test outcomes
tests <- array(0, dim = c(nindividuals, length(psens)))
colnames(tests) <- c("test1", "test2")

#for each badger and each test, simulate test outcome
for(i in 1:length(inf)){
  for(j in 1:length(psens)){
    tests[i, j] <- rbinom(1, 1, ifelse(inf[i] == 1, psens[j], 1-pspec[j]))}}
#how many tests?
###choose number of tests to infer results from
ntests <- 2

#get table of frequencies
binop <- 2^seq(0, ntests-1)
testbin <- tests[, 1:ntests] %*% binop
testcounts <- tabulate(testbin + 1, nbins = 2^ntests)
testcounts

#create omega matrix of binary sequence
omega <- expand.grid(replicate(ntests, c(0, 1), simplify = FALSE))
omega <- as.matrix(omega)
omega <- t(omega)

## Define parameters you want to report on
params <- c("pprev", "psens", "pspec")

code  <- nimbleCode({
  
  for(i in 1:n) {
    pinf[i] <- pprev * prod(omega[1:nT, i] * psens[1:nT] + (1 - omega[1:nT, i]) * (1 - psens[1:nT])) +
      (1 - pprev) * prod(omega[1:nT, i] * (1 - pspec[1:nT]) + (1 - omega[1:nT, i]) * (pspec[1:nT]))
  }
  
  Te[1:n] ~ dmulti(pinf[1:n], N)
  
  
  pprev ~ dunif(0,1)
  
  for(j in 1:nT) {
    psens[j] ~ dunif(0, 1)
    pspec[j] ~ dunif(0, 1)
  }
  
})

consts <- list(n = length(testcounts),
               nT = ntests, N = sum(testcounts), omega = omega)

data <- list(
  Te = testcounts)

inits <- list(
  pprev = runif(1, 0, 1),
  psens = runif(ntests, 0, 1),
  pspec = runif(ntests, 0, 1)
)

model <- nimbleModel(code, constants = consts, data = data, inits = inits)

cModel <- compileNimble(model)

config <- configureMCMC(model)

rMCMC <- buildMCMC(config)

cMCMC <- compileNimble(rMCMC, project = model)

system.time(run <- runMCMC(cMCMC, 
                           niter = 500000, 
                           nburnin = 24000, 
                           nchains = 3, 
                           progressBar = TRUE, 
                           summary = TRUE, 
                           samplesAsCodaMCMC = TRUE, 
                           thin = 1))

saveRDS(run, file = "run2_2test.rds")

```

#### And finally run the analysis with 3 test scenario with an uninformative third test and save the output.
## Set up a three test scenario with the 3rd test being uninformative

``` {r}
psens <- c(0.9, 0.9, 0.5)
pspec <- c(0.75, 0.75, 0.5)
pprev <- 0.3
nindividuals <- 1000
true_values <- c(pprev, psens[1], pspec[1])
true_parameter <- c("Prevalence", "Sensitivity", "Specificity")
truth <- data.frame(true_parameter, true_values)  
```

#### Simulate test outcomes and run the analysis

```{r, message=FALSE}

#simulate infection status
inf <- rbinom(nindividuals, 1, pprev)

#set up empty array of test outcomes
tests <- array(0, dim = c(nindividuals, length(psens)))
colnames(tests) <- c("test1", "test2", "test3")

#for each badger and each test, simulate test outcome
for(i in 1:length(inf)){
  for(j in 1:length(psens)){
    tests[i, j] <- rbinom(1, 1, ifelse(inf[i] == 1, psens[j], 1-pspec[j]))}}

###choose number of tests to infer results from
ntests <- 3

#get table of frequencies
binop <- 2^seq(0, ntests-1)
testbin <- tests[, 1:ntests] %*% binop
testcounts <- tabulate(testbin + 1, nbins = 2^ntests)

#create omega matrix of binary sequence
omega <- expand.grid(replicate(ntests, c(0, 1), simplify = FALSE))
omega <- as.matrix(omega)
omega <- t(omega)

## Define parameters to report on
params <- c("pprev", "psens", "pspec")

## Run NIMBLE code
code <- nimbleCode({
  
  for(i in 1:n) {
    pinf[i] <- pprev * prod(omega[1:nT, i] * psens[1:nT] + (1 - omega[1:nT, i]) * (1 - psens[1:nT])) +
      (1 - pprev) * prod(omega[1:nT, i] * (1 - pspec[1:nT]) + (1 - omega[1:nT, i]) * (pspec[1:nT]))
  }
  
  Te[1:n] ~ dmulti(pinf[1:n], N)
  
  pprev ~ dunif(0,1)
  
  # Specify different priors for each psens
  psens[1] ~ dunif(0.5, 1)
  psens[2] ~ dunif(0, 1)
  psens[3] ~ dunif(0, 1)
  
  for(j in 1:nT) {
    pspec[j] ~ dunif(0, 1)
  }
  
})

consts <- list(n = length(testcounts),
               nT = ntests, N = sum(testcounts), omega = omega)

data <- list(
  Te = testcounts)

inits <- list(
  pprev = runif(1, 0, 1),
  psens = c(runif(1, 0.5, 1), runif(1, 0, 1), runif(1, 0, 1)),
  pspec = runif(ntests, 0, 1)
)

model <- nimbleModel(code, constants = consts, data = data, inits = inits)

cModel <- compileNimble(model)

config <- configureMCMC(model)

rMCMC <- buildMCMC(config)

cMCMC <- compileNimble(rMCMC, project = model)

system.time(run <- runMCMC(cMCMC, 
                           niter = 500000, 
                           nburnin = 24000, 
                           nchains = 3, 
                           progressBar = TRUE, 
                           summary = TRUE, 
                           samplesAsCodaMCMC = TRUE, 
                           thin = 1))

saveRDS(run, file = "run3_3test5050.rds")

```

#### Now load the results and organise ready to plot.

```{r, message=FALSE}

run1 <- readRDS("run1_3test.rds")
run2 <- readRDS("run2_2test.rds")
run3 <- readRDS("run3_3test5050.rds")

r1_sum <- run1$summary
r1_sum <- as.matrix(r1_sum$all.chains[, 1])
r1_samp <- as.matrix(run1$samples)

r1_samp <- r1_samp %>%
  as.data.frame() %>%
  rename(pprev = 1, psens = 2, psens2 = 3, psens3 = 4, pspec = 5, pspec2 = 6, pspec3 = 7) %>%
  pivot_longer(cols = c(pprev, psens, pspec, psens3, pspec3),  values_to = "Estimate", names_to = "Inferred_parameter" ) %>%
  mutate(NumberofTests = "3 (Informatively bad 3rd)") %>%
  select(Inferred_parameter, Estimate, NumberofTests) %>%
  mutate(Truth = rep(c(0.3, 0.9, 0.75, 0.1, 0.05), times = 7140000/5)) %>%
  mutate(Mean = rep(c(r1_sum[1], r1_sum[2], r1_sum[5], r1_sum[3], r1_sum[6]), times = 7140000/5))

r2_sum <- run2$summary
r2_sum <- as.matrix(r2_sum$all.chains[, 1])
r2_samp <- as.matrix(run2$samples)

r2_samp <- r2_samp %>%
  as.data.frame() %>%
  rename(pprev = 1, psens = 2, psens2 = 3, pspec = 4, pspec2 = 5) %>%
  select(pprev, psens, pspec) %>%
  pivot_longer(cols = c(pprev, psens, pspec),  values_to = "Estimate", names_to = "Inferred_parameter" ) %>%
  mutate(NumberofTests = 2) %>%
  select(Inferred_parameter, Estimate, NumberofTests) %>%
  mutate(Truth = rep(c(0.3, 0.9, 0.75), times = 4284000/3)) %>%
  mutate(Mean = rep(c(r2_sum[1], r2_sum[2], r2_sum[4]), times = 4284000/3))

r3_sum <- run3$summary
r3_sum <- as.matrix(r3_sum$all.chains[, 1])
r3_samp <- as.matrix(run3$samples)

r3_samp <- r3_samp %>%
  as.data.frame() %>%
  rename(pprev = 1, psens = 2, psens2 = 3, psens3 = 4, pspec = 5, pspec2 = 6, pspec3 = 7) %>%
  pivot_longer(cols = c(pprev, psens, pspec, psens3, pspec3),  values_to = "Estimate", names_to = "Inferred_parameter" ) %>%
  mutate(NumberofTests = "3 (Uninformative 3rd)") %>%
  select(Inferred_parameter, Estimate, NumberofTests) %>%
  mutate(Truth = rep(c(0.3, 0.9, 0.75, 0.5, 0.5), times = 7140000/5)) %>%
  mutate(Mean = rep(c(r3_sum[1], r3_sum[2], r3_sum[5], r3_sum[3], r3_sum[6]), times = 7140000/5))



data <- rbind(r1_samp, r2_samp, r3_samp)
data$NumberofTests <- as.factor(data$NumberofTests)

```

#### And finally we can plot.

```{r, message=FALSE}

ggplot(data, aes(x = Inferred_parameter, y = Estimate, fill = Inferred_parameter)) +
  geom_violin(position = "dodge") +
  geom_hline(aes(yintercept = Truth, colour = Inferred_parameter), linetype = 2) +
  stat_summary(fun = "mean", geom = "point") +
  facet_grid(~ NumberofTests) +
  theme_bw() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), text = element_text(size = 15)) +
  labs(x = "Number of Tests", fill = "Inferred parameter", colour = "Inferred parameter") +
  scale_fill_discrete(labels = c("Prevalence", "Sensitivity test A", "Sensitivity test C", "Specificity test A", "Specificity test C")) +
  scale_colour_discrete(labels = c("Prevalence", "Sensitivity test A", "Sensitivity test C", "Specificity test A", "Specificity test C"))

```
